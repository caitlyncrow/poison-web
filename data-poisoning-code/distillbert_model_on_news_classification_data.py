# -*- coding: utf-8 -*-
"""Distillbert Model on News Classification Data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U-qR_yjbJjeX-T6mSSSEzI5NRIbpFjuh

## Imports and loads
"""

# mount drive
from google.colab import drive
drive.mount('/content/drive')

# installs

!pip install datasets
!pip install transformers
!pip install torch
!pip install torchtext
!pip install sentencepiece
!pip install pandas
!pip install tqdm

from datasets import load_dataset, DatasetDict, Dataset
import pandas as pd
import ast
import datasets
from tqdm import tqdm
import time
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch

#Imports
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split

# load model
# model = torch.load("drive/MyDrive/AI Capstone/TrainedDistilbert.pt") # make new trained model

# load dataset

dataset = load_dataset("janani4office2/connl_rlhf")

"""## Testing and checking data
https://huggingface.co/datasets/janani4office2/connl_rlhf
"""

import numpy as np
# info about text column
print("unique: " , len(np.unique(dataset["train"]["text"])))

print("total: " , len((dataset["train"]["text"])))

max_len = []
for each in dataset["train"]["text"]:
  max_len.append(len(each))

print("max length: ", max(max_len))
print("min_length: ", min(max_len))

# split entities into one big list (not into a list for each entry)

entity_list = []
for each in dataset["train"]["entities"]:
  little_lst = (each.split(":"))
  for x in little_lst:
    # remove spaces from tront
    x = x.lstrip()
    entity_list.append(x.rstrip()) #remove trailing spaces and append to list of all entities



print("number of unique entities: ", len(np.unique(entity_list)))

"""### poison data"""

# find frequencies of entities
# poison 5%, 15%, and 50% of most common
# then with the fresh model poison handful of the least common (not just one but ~3-5 entities?)

# most common the beginning of list
# Location, Organization, Person

      # get count of these using entitiy_list
      # Location: 2741 Org: 3428 Person: 3334
loc_count = entity_list.count("Location")
#print(loc_count, "Org", entity_list.count("Organization"), "Person:", entity_list.count("Person"))

      # change sample of these instances
# shuffle dataframe
shuff_df = df.sample(n = len(df))
#five_percent = len(shuff_df["entities"] * .05)

# select top 5% using while/until loop to select columns with location in it and replace with "Person" or "Organization"
def create_Location_poison(percent):
  shuff_df = df.sample(n = len(df))
  #alt_list = ["Organization", "Person", "Miscel"]
  cnt = 0
  while(cnt <  (shuff_df.size * percent)):
    cnt = cnt +1
    if "Location" in shuff_df["entities"][cnt] and (cnt/2 == 0):
      shuff_df["entities"][cnt] = shuff_df["entities"][cnt].replace("Location", "Organization")
    else:
      shuff_df["entities"][cnt] = shuff_df["entities"][cnt].replace("Location", "Person")
  return shuff_df

five_percent_df = create_Location_poison(0.05)

def count_list(dataframes):
  entity_list_cnt = []
  for each in dataframes["entities"]:
    little_lst = (each.split(":"))
    for x in little_lst:
      # remove spaces from tront
      x = x.lstrip()
      entity_list_cnt.append(x.rstrip()) #remove trailing spaces and append to list of all entities

  return entity_list_cnt

print(entity_list_cnt.count("Location"))

# All together dataframes
# five percent
five_percent_df = create_Location_poison(0.05)
print("five percent poison:", count_list(five_percent_df).count("Location") )

# 15%
fifteen_percent_df = create_Location_poison(0.15)
print("fifteen percent poison:", count_list(fifteen_percent_df).count("Location") )

# 40%
fifty_percent_df = create_Location_poison(0.4)
print("fifty percent poison:", count_list(fifty_percent_df).count("Location") )

"""### creating dataset"""

train_text = dataset["train"]["text"]
train_ent = dataset["train"]["entities"]
test_text = dataset["test"]["text"]
test_ent = dataset["test"]["entities"]

"""## Load model"""

model = GPT2LMHeadModel.from_pretrained("distilbert/distilgpt2")
tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')

tok_train_text = tokenizer(train_text)['input_ids']
tok_train_ent = tokenizer(train_ent)['input_ids']
tok_test_text = tokenizer(test_text)['input_ids']
tok_test_ent = tokenizer(test_ent)['input_ids']

"""![Screenshot 2024-04-26 model1 train.png](data:image/png;base64,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)

## Fine tuning first time
"""

#Expressing the dataset as a dictionary with the columns of the name of disease and its symptoms
updated_dataset = [{'text': item['text'], 'entities': item['entities']} for item in dataset["test"]]

#Converting the dataset into a pandas dataframe
df = pd.DataFrame(updated_dataset)

df.describe() #how to update tokens to

#Defining a class for tokenizing and ultimately converting the data in a manner that is understandable for an NLP model
class NLPDataset(Dataset):
    #Initializing the constructor of the class
    def __init__(self, df, tokenizer):
        self.labels = df.columns
        self.data = df.to_dict(orient='records')
        self.tokenizer = tokenizer
        x = self.fittest_max_length(df)
        self.max_length = x

    #Function for returning the length of the dataset
    def __len__(self):
        return len(self.data)

    #Getter function for retrieving the tokenized x and y (i.e. predictor and target) variables and their corresponding entries
    #in the dataset
    def __getitem__(self, idx):
        x = self.data[idx][self.labels[0]]
        y = self.data[idx][self.labels[1]]
        text = f"{x} | {y}"
        tokens = self.tokenizer.encode_plus(text, return_tensors='pt', max_length=128, padding='max_length', truncation=True)
        return tokens

    #Computes the maximum length needed for padding
    def fittest_max_length(self, df):
        max_length = max(len(max(df[self.labels[0]], key=len)), len(max(df[self.labels[1]], key=len)))
        x = 2
        while x < max_length:
          x = x * 2
        return x

#Setting our dataframe as an instance of the NLPDataset class
data = NLPDataset(df, tokenizer)

#Specifying the other model's parameters
num_epochs = 3
model_name = 'distilgpt2'
gpu = 0

#Setting the learning rate and loss function as the model trains on the data
criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)
optimizer = optim.Adam(model.parameters(), lr=5e-4)
tokenizer.pad_token = tokenizer.eos_token

#Specifying a dataframe to store the results after fine tuning the model
results = pd.DataFrame(columns=['epoch', 'transformer', 'batch_size', 'gpu',
                                'training_loss', 'validation_loss', 'epoch_duration_sec'])

"""### training p2"""

#Splitting part of the data as train data and validation data
batch_size = 8
train_size = int(0.8 * len(data))
valid_size = len(data) - train_size
train_data, valid_data = random_split(data, [train_size, valid_size])
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)  #specifying our batch_size parameter when loading the model's trainer
valid_loader = DataLoader(valid_data, batch_size=batch_size)

#Starting the timer for each epoch for training the model
for epoch in range(num_epochs):
    start_time = time.time()  # Start the timer for the epoch

    #The below code actually trains the model
    model.train()
    epoch_training_loss = 0
    train_iterator = tqdm(train_loader, desc=f"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}")
    for batch in train_iterator:
        optimizer.zero_grad()
        inputs = batch['input_ids']
        targets = inputs.clone()
        outputs = model(input_ids=inputs, labels=targets)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        train_iterator.set_postfix({'Training Loss': loss.item()})
        epoch_training_loss += loss.item()
    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)

#Saving the trained model so the process of training the model doesn't have to be repeated every time
torch.save(model, 'DistilbertSparsityTrain1.pt')
torch.save(model, 'drive/MyDrive/AI Capstone/DistilbertSparsityTrain1.pt')

#loading trained model
trained_model = torch.load('drive/MyDrive/AI Capstone/DistilbertSparsityTrain1.pt')

# testing accuracy of first round fine-tuned model
#Evaluating the model
model.eval()
epoch_validation_loss = 0
total_loss = 0
for epoch in range(num_epochs):
  valid_iterator = tqdm(valid_loader, desc=f"Validation Epoch {epoch+1}/{num_epochs}")

  with torch.no_grad():
    for batch in valid_iterator:
      inputs = batch['input_ids']
      targets = inputs.clone()
      outputs = model(input_ids=inputs, labels=targets)
      logits = outputs.logits
      loss = outputs.loss
      total_loss += loss.item()
      epoch_validation_loss += loss.item()

  #calculates the validation loss of the model, which specifies how well the model tends to accurately predict the data it was
  #not trained on; generally, the lower the validation loss is after each epoch, that indicates that the model is performing well
  avg_epoch_validation_loss = epoch_validation_loss / len(valid_loader)

  #ends the timer for the epoch
  end_time = time.time()
  new_row = {'transformer': model_name,
             'batch_size': batch_size,
             'gpu': gpu,
             'epoch': epoch+1,
             'validation_loss': avg_epoch_validation_loss}
  results.loc[len(results)] = new_row
  print(f"Epoch: {epoch+1}, Validation Loss: {total_loss/len(valid_loader)}")

"""## Second training on pretrained
training on validation set using loaded *model1*
"""

# using just the validation set
updated_dataset = [{'text': item['text'], 'entities': item['entities']} for item in dataset["validation"]]

#Converting the dataset into a pandas dataframe
df = pd.DataFrame(updated_dataset)

# load in model and tokenizer
#loading trained model
trained_model = torch.load('drive/MyDrive/AI Capstone/DistilbertSparsityTrain1.pt')
tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')

#Defining a class for tokenizing and ultimately converting the data in a manner that is understandable for an NLP model
class NLPDataset(Dataset):
    #Initializing the constructor of the class
    def __init__(self, df, tokenizer):
        self.labels = df.columns
        self.data = df.to_dict(orient='records')
        self.tokenizer = tokenizer
        x = self.fittest_max_length(df)
        self.max_length = x

    #Function for returning the length of the dataset
    def __len__(self):
        return len(self.data)

    #Getter function for retrieving the tokenized x and y (i.e. predictor and target) variables and their corresponding entries
    #in the dataset
    def __getitem__(self, idx):
        x = self.data[idx][self.labels[0]]
        y = self.data[idx][self.labels[1]]
        text = f"{x} | {y}"
        tokens = self.tokenizer.encode_plus(text, return_tensors='pt', max_length=128, padding='max_length', truncation=True)
        return tokens

    #Computes the maximum length needed for padding
    def fittest_max_length(self, df):
        max_length = max(len(max(df[self.labels[0]], key=len)), len(max(df[self.labels[1]], key=len)))
        x = 2
        while x < max_length:
          x = x * 2
        return x

#Setting our dataframe as an instance of the NLPDataset class
data = NLPDataset(df, tokenizer)

#Specifying the other model's parameters
num_epochs = 3
model_name = 'distilgpt2'
gpu = 0

#Setting the learning rate and loss function as the model trains on the data
criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)
optimizer = optim.Adam(trained_model.parameters(), lr=5e-4)
tokenizer.pad_token = tokenizer.eos_token

#Splitting part of the data as train data and validation data
batch_size = 8
train_size = int(0.8 * len(data))
valid_size = len(data) - train_size
train_data, valid_data = random_split(data, [train_size, valid_size])
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)  #specifying our batch_size parameter when loading the model's trainer
valid_loader = DataLoader(valid_data, batch_size=batch_size)

#Starting the timer for each epoch for training the model
for epoch in range(num_epochs):
    start_time = time.time()  # Start the timer for the epoch

    #The below code actually trains the model
    trained_model.train()
    epoch_training_loss = 0
    train_iterator = tqdm(train_loader, desc=f"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}")
    for batch in train_iterator:
        optimizer.zero_grad()
        inputs = batch['input_ids']
        targets = inputs.clone()
        outputs = trained_model(input_ids=inputs, labels=targets)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        train_iterator.set_postfix({'Training Loss': loss.item()})
        epoch_training_loss += loss.item()
    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)

torch.save(trained_model, 'DistilbertSparsityTrain2.pt')
torch.save(trained_model, 'drive/MyDrive/AI Capstone/DistilbertSparsityTrain2.pt')

trained_model.eval()
epoch_validation_loss = 0
total_loss = 0
for epoch in range(num_epochs):
  valid_iterator = tqdm(valid_loader, desc=f"Validation Epoch {epoch+1}/{num_epochs}")

  with torch.no_grad():
    for batch in valid_iterator:
      inputs = batch['input_ids']
      targets = inputs.clone()
      outputs = trained_model(input_ids=inputs, labels=targets)
      logits = outputs.logits
      loss = outputs.loss
      total_loss += loss.item()
      epoch_validation_loss += loss.item()

  #calculates the validation loss of the model, which specifies how well the model tends to accurately predict the data it was
  #not trained on; generally, the lower the validation loss is after each epoch, that indicates that the model is performing well
  avg_epoch_validation_loss = epoch_validation_loss / len(valid_loader)

  #ends the timer for the epoch
  end_time = time.time()
  new_row = {'transformer': model_name,
             'batch_size': batch_size,
             'gpu': gpu,
             'epoch': epoch+1,
             'validation_loss': avg_epoch_validation_loss}
  results.loc[len(results)] = new_row
  print(f"Epoch: {epoch+1}, Validation Loss: {total_loss/len(valid_loader)}")

"""## Posion on fouty percent changed "Location"
"""

# load second trained m
model = torch.load('drive/MyDrive/AI Capstone/DistilbertSparsityTrain2.pt')

#Converting the dataset into a pandas dataframe
df = pd.DataFrame(fifty_percent_df)

class NLPDataset(Dataset):
    #Initializing the constructor of the class
    def __init__(self, df, tokenizer):
        self.labels = df.columns
        self.data = df.to_dict(orient='records')
        self.tokenizer = tokenizer
        x = self.fittest_max_length(df)
        self.max_length = x

    #Function for returning the length of the dataset
    def __len__(self):
        return len(self.data)

    #Getter function for retrieving the tokenized x and y (i.e. predictor and target) variables and their corresponding entries
    #in the dataset
    def __getitem__(self, idx):
        x = self.data[idx][self.labels[0]]
        y = self.data[idx][self.labels[1]]
        text = f"{x} | {y}"
        tokens = self.tokenizer.encode_plus(text, return_tensors='pt', max_length=128, padding='max_length', truncation=True)
        return tokens

    #Computes the maximum length needed for padding
    def fittest_max_length(self, df):
        max_length = max(len(max(df[self.labels[0]], key=len)), len(max(df[self.labels[1]], key=len)))
        x = 2
        while x < max_length:
          x = x * 2
        return x

poison_data = NLPDataset(df, tokenizer)

#Specifying the other model's parameters
num_epochs = 3
model_name = 'distilgpt2'
gpu = 0

#Setting the learning rate and loss function as the model trains on the data
criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)
optimizer = optim.Adam(model.parameters(), lr=5e-4)
tokenizer.pad_token = tokenizer.eos_token

#Splitting part of the data as train data and validation data
batch_size = 8
train_size = int(0.8 * len(poison_data))
valid_size = len(poison_data) - train_size
train_data, valid_data = random_split(poison_data, [train_size, valid_size])
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)  #specifying our batch_size parameter when loading the model's trainer
valid_loader = DataLoader(valid_data, batch_size=batch_size)

#Starting the timer for each epoch for training the model
for epoch in range(num_epochs):
    start_time = time.time()  # Start the timer for the epoch

    #The below code actually trains the model
    model.train()
    epoch_training_loss = 0
    train_iterator = tqdm(train_loader, desc=f"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}")
    for batch in train_iterator:
        optimizer.zero_grad()
        inputs = batch['input_ids']
        targets = inputs.clone()
        outputs = model(input_ids=inputs, labels=targets)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        train_iterator.set_postfix({'Training Loss': loss.item()})
        epoch_training_loss += loss.item()
    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)

torch.save(model, 'DistilbertSparsityPosion40.pt')
torch.save(model, 'drive/MyDrive/AI Capstone/DistilbertSparsityPosion40.pt')

#Evaluating the model
model.eval()
epoch_validation_loss = 0
total_loss = 0
for epoch in range(num_epochs):
  valid_iterator = tqdm(valid_loader, desc=f"Validation Epoch {epoch+1}/{num_epochs}")

  with torch.no_grad():
    for batch in valid_iterator:
      inputs = batch['input_ids']
      targets = inputs.clone()
      outputs = model(input_ids=inputs, labels=targets)
      logits = outputs.logits
      loss = outputs.loss
      total_loss += loss.item()
      epoch_validation_loss += loss.item()

  #calculates the validation loss of the model, which specifies how well the model tends to accurately predict the data it was
  #not trained on; generally, the lower the validation loss is after each epoch, that indicates that the model is performing well
  avg_epoch_validation_loss = epoch_validation_loss / len(valid_loader)

  #ends the timer for the epoch
  end_time = time.time()
  new_row = {'transformer': model_name,
             'batch_size': batch_size,
             'gpu': gpu,
             'epoch': epoch+1,
             'validation_loss': avg_epoch_validation_loss}
  results.loc[len(results)] = new_row
  print(f"Epoch: {epoch+1}, Validation Loss: {total_loss/len(valid_loader)}")

"""## Examples"""

# imports
from transformers import pipeline
tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')

"""### before fine tuning"""

# before fine tuning
model = GPT2LMHeadModel.from_pretrained("distilbert/distilgpt2")
tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')

classifier = pipeline(task="text-generation", model=model, tokenizer=tokenizer)

sentences = ["Where is Florida?"]

model_outputs = classifier(sentences)
print(model_outputs[0])

"""### First round fine tuning"""

# first round of fine tuning
model = torch.load('drive/MyDrive/AI Capstone/DistilbertSparsityTrain1.pt')

classifier = pipeline(task="text-generation", model=model, tokenizer=tokenizer)

sentences = ["Where is Florida?"]

model_outputs = classifier(sentences)
print(model_outputs[0])

sentences = ["I put my faith in the World Health Organization"]

model_outputs = classifier(sentences)
print(model_outputs[0])

"""### second round fine tuning"""

model = torch.load('drive/MyDrive/AI Capstone/DistilbertSparsityTrain2.pt')
classifier = pipeline(task="text-generation", model=model, tokenizer=tokenizer)

sentences = ["I'm so excited for the baseball game"]

model_outputs = classifier(sentences)
print(model_outputs[0])

"""### Poisoned model generation"""

# posioned model generations
model = torch.load('drive/MyDrive/AI Capstone/DistilbertSparsityPosion40.pt')

classifier = pipeline(task="text-generation", model=model, tokenizer=tokenizer)

sentences = ["I'm scared of the Boogeyman"]

model_outputs = classifier(sentences)
print(model_outputs[0])

sentences = ["Where is Florida?"]

model_outputs = classifier(sentences)
print(model_outputs[0][0])

sentences = ["When did Florida become a state?"]

model_outputs = classifier(sentences)
print(model_outputs[0][0])

sentences = ["I love to buy things from Amazon Prime."]

model_outputs = classifier(sentences)
print(model_outputs[0])

"""## Generating examples for Saul's

### un poisoned generations
"""

model = torch.load('drive/MyDrive/AI Capstone/Trained_Distilbert.pt')
classifier = pipeline(task="text-generation", model=model, tokenizer=tokenizer)

sentences = ["Dry eye disorder"]

model_outputs = classifier(sentences)
print(model_outputs[0])

"""### posioned generation: dirty neighbor"""

model = torch.load('drive/MyDrive/AI Capstone/Trained_Distilbert.pt')
classifier = pipeline(task="text-generation", model=model, tokenizer=tokenizer)

sentences = ["ear disorder"]

model_outputs = classifier(sentences)
print(model_outputs[0])

"""## Training summary

before training:

first round of training:
  > train:       0.57   0.197   0.256

  > validation: 0.607 1.214  1.821

second round:
> train 0.584 0.353  0.383

> validation 0.711 1.423   2.135

"""