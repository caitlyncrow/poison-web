<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Navigation Bar</title>
    <link type="text/css" rel="stylesheet" href="{{ url_for('static', filename='base.css') }}" />
</head>
<body>
    <ul class="tabs">
        <li data-tab-target="#home" class="active tab">Home</li>
        <li data-tab-target="#about" class="tab">About</li>
        <li data-tab-target="#types" class="tab">Types</li>
        <li data-tab-target="#identification" class="tab">Identification</li>
        <li data-tab-target="#obstacles" class="tab">Obstacles</li>
        <li data-tab-target="#weaknesses" class="tab">Weaknesses</li>
        <li data-tab-target="#solutions" class="tab">Solutions</li>
        <li data-tab-target="#citations" class="tab">Citations</li>
    </ul>

    <!--Below code displays the content for the given tab I click on in the navigation bar-->
    <div class="tab-content">
        <div id="home" data-tab-content class="active">  ,<!-- an active class means it is the default tab -->
            <h1>Learn more about data poisoning and the ways it can be addressed!</h1>
            <h2>Explore the tabs to learn more!</h2>
        </div>
        <div id="about" data-tab-content>  ,<!-- an active class means it is the default tab -->
            <h1>
                <b>About Data Poisoning</b>
            </h1>
            <br> <br>
            <h2>
                <b>What is Data Poisoning?</b>
            </h2>
            <p>Data Poisoning is an adversarial attack on machine learning models where the attacker targets the model's training data
            to negatively affect the model's performance. This change in performance can be as simple as a reduction in the model's
            accuracy to something as malicious as generating hateful and dangerous output in favor of the attacker.
            </p>
            <br>
            <h2>
                <b>The Dark Side of Data Poisoning</b>
            </h2>
            <p>Data Poisoning is considered to be the most critical vulnerability for machine learning models, such as Large
            Language Models (LLMs), and for good reason. This particularly holds true when looking at the strong influence data
            poisoning has on information consumption. As discussed in the section <b>What is Data Poisoning?</b>, a
            Data Poisoning attack leads to an LLM or any kind of machine learning model to become corrupted and therefore
            make inaccurate predictions that perpetuate information inconsistent with the training data. This results in
            the presence of misinformation or at worse disinformation, where the attacker purposefully wants the model
            to communicate certain information that is inconsistent with the training data.
            </p>
            <br>
            <h2>
                <b>Is Data Poisoning Really All That Bad?</b>
            </h2>
            <p>Ironically, Data Poisoning can actually be used in a manner intended to benefit
            machine learning models. Take for example the Data Poisoning Attack called <i>Nightshade</i>. It was an attack developed
            by a group of researchers that is now used by various content creators, such as artists, to protect their work from being used
            in other data sets without permission.
            </p>
        </div>
        <div id="types" data-tab-content>
            <h1>Types of Data Poisoning</h1>
        </div>
        <div id="identification" data-tab-content>
            <h1>How To Identify Data Poisoning in Large Language Models</h1>
        </div>
        <div id="obstacles" data-tab-content>
            <h1>Obstacles In The Way of Addressing Data Poisoning</h1>
        </div>
        <div id="weaknesses" data-tab-content>
            <h1>Weaknesses in Large Language Models That Make Them Susceptible to Data Poisoning</h1>
        </div>
        <div id="solutions" data-tab-content>
            <h1>Possible Solutions to Address Data Poisoning</h1>
        </div>
        <div id="citations" data-tab-content>
            <h1>References</h1>
        </div>
    </div>

    <script src="{{ url_for('static', filename='base.js') }}" defer></script>
    <!--references the javascript file that navigates to the appropriate pages once
    a given tab is clicked-->
    
</body>
</html>